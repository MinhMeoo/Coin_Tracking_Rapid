import requests
import pandas as pd
import os
from config import SYMBOLS_LIST

import time
from datetime import datetime, timedelta
from typing import Optional


INTERVAL_MS = 15 * 60 * 1000  # 15 minutes in ms
DATA_FOLDER = "/Users/minhmeoow/MiniProject_Python/Coin_tracking_rapid/datafiles"
os.makedirs(DATA_FOLDER, exist_ok=True)


def get_binance_server_time() -> int:
    """L·∫•y serverTime (ms) t·ª´ Binance futures (fapi)."""
    url = "https://fapi.binance.com/fapi/v1/time"
    resp = requests.get(url, timeout=5)
    resp.raise_for_status()
    return int(resp.json()["serverTime"])
#  Ham nay fetch du data 30 nen, thuong duoc call vao luc 6h sang

def fetch_15m_closed_klines(
    symbol: str,
    limit: int = 30,
    use_server_time: bool = True,
    server_ms: Optional[int] = None,
    retries: int = 1,
    delay_retry: float = 1.0,
) -> Optional[pd.DataFrame]:
    """
    L·∫•y `limit` n·∫øn 15m ƒë√£ ƒë√≥ng cho symbol.
    
    Args:
        symbol (str): v√≠ d·ª• "BTCUSDT"
        limit (int): s·ªë l∆∞·ª£ng n·∫øn c·∫ßn l·∫•y
        use_server_time (bool): n·∫øu True th√¨ d√πng server time Binance, False d√πng local time
        server_ms (Optional[int]): serverTime ƒë√£ c√≥ s·∫µn, n·∫øu None s·∫Ω t·ª± fetch
        retries (int): s·ªë l·∫ßn retry khi l·ªói request
        delay_retry (float): th·ªùi gian ch·ªù (gi√¢y) gi·ªØa c√°c l·∫ßn retry
    
    Returns:
        Optional[pd.DataFrame]: b·∫£ng d·ªØ li·ªáu n·∫øn ho·∫∑c None n·∫øu l·ªói
    """
    url = "https://fapi.binance.com/fapi/v1/klines"

    for attempt in range(1, retries + 1):
        try:
            # x√°c ƒë·ªãnh endTime
            if use_server_time:
                if server_ms is None:
                    server_ms = get_binance_server_time()
                boundary_ms = (server_ms // INTERVAL_MS) * INTERVAL_MS
            else:
                # fallback d√πng local UTC time
                now = datetime.utcnow()
                boundary = now.replace(second=0, microsecond=0) - timedelta(minutes=now.minute % 15)
                boundary_ms = int(boundary.timestamp() * 1000)

            # endTime = boundary_ms - 1 ‚Üí ch·ªâ l·∫•y n·∫øn ƒë√£ ƒë√≥ng
            end_time_ms = boundary_ms - 1

            params = {
                "symbol": symbol.upper(),
                "interval": "15m",
                "limit": limit,
                "endTime": end_time_ms
            }

            resp = requests.get(url, params=params, timeout=10)
            resp.raise_for_status()
            data = resp.json()

            if not data:
                # symbol kh√¥ng h·ª£p l·ªá ho·∫∑c th·ªã tr∆∞·ªùng qu√° m·ªõi
                return None

            df = pd.DataFrame(data, columns=[
                "open_time", "open", "high", "low", "close", "volume",
                "close_time", "quote_asset_volume", "number_of_trades",
                "taker_buy_base", "taker_buy_quote", "ignore"
            ])

            # convert ki·ªÉu
            df["open_time"] = pd.to_datetime(df["open_time"], unit="ms")
            df["close_time"] = pd.to_datetime(df["close_time"], unit="ms")
            numeric_cols = ["open", "high", "low", "close", "volume"]
            df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors="coerce")

            # t√≠nh th√™m c·ªôt
            df["delta_change"] = (df["close"] - df["open"]) / df["open"]
            df["average_volume_20"] = pd.to_numeric(df["volume"], errors="coerce").rolling(20).mean().shift(1)

            # gi·ªØ c√°c c·ªôt c·∫ßn thi·∫øt
            df_out = df[["open_time", "open", "high", "low", "close", "volume", "delta_change", "average_volume_20"]].copy()
            df_out.rename(columns={"open_time": "timestamp"}, inplace=True)

            return df_out

        except Exception as e:
            print(f"[{datetime.now()}] ‚ö†Ô∏è Fetch error for {symbol} (attempt {attempt}/{retries}): {e}")
            if attempt < retries:
                time.sleep(delay_retry)
                continue
            else:
                return None

#  ham nay call vao moi 15p

def fetch_append_latest_15m_candle(
    symbol: str,
    excel_file: str,
    server_ms: Optional[int] = None,
    retries: int = 2,
    delay_retry: float = 1.0,
) -> None:
    """
    L·∫•y 1 n·∫øn 15m m·ªõi nh·∫•t v√† append v√†o cu·ªëi file Excel.
    
    Args:
        symbol (str): v√≠ d·ª• "BTCUSDT"
        excel_file (str): ƒë∆∞·ªùng d·∫´n file Excel
        server_ms (Optional[int]): Th·ªùi gian server Binance (ms). N·∫øu None s·∫Ω t·ª± fetch.
        retries (int): s·ªë l·∫ßn retry khi l·ªói request
        delay_retry (float): th·ªùi gian ch·ªù (gi√¢y) gi·ªØa c√°c l·∫ßn retry
    """
    try:
        # ƒë·ªçc d·ªØ li·ªáu c≈© n·∫øu c√≥
        if os.path.exists(excel_file):
            df_old = pd.read_excel(excel_file)
        else:
            df_old = pd.DataFrame()

        # # l·∫•y th·ªùi gian server Binance n·∫øu ch∆∞a c√≥
        # if server_ms is None:
        #     for attempt in range(1, retries + 1):
        #         try:
        #             server_ms = get_binance_server_time()
        #             break
        #         except Exception as e:
        #             print(f"[{datetime.now()}] ‚ö†Ô∏è Error get server time (attempt {attempt}/{retries}): {e}")
        #             if attempt < retries:
        #                 time.sleep(delay_retry)
        #                 continue
        #             else:
        #                 return

        boundary_ms = (server_ms // INTERVAL_MS) * INTERVAL_MS
        end_time_ms = boundary_ms - 1  # n·∫øn ƒë√≥ng ngay tr∆∞·ªõc boundary

        url = "https://fapi.binance.com/fapi/v1/klines"
        params = {
            "symbol": symbol.upper(),
            "interval": "15m",
            "limit": 1,
            "endTime": end_time_ms
        }

        resp = requests.get(url, params=params, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        if not data:
            print(f"[{datetime.now()}] ‚ö†Ô∏è No new candle for {symbol}")
            return

        df_new = pd.DataFrame(data, columns=[
            "open_time", "open", "high", "low", "close", "volume",
            "close_time", "quote_asset_volume", "number_of_trades",
            "taker_buy_base", "taker_buy_quote", "ignore"
        ])

        # convert ki·ªÉu
        df_new["open_time"] = pd.to_datetime(df_new["open_time"], unit="ms")
        df_new["close_time"] = pd.to_datetime(df_new["close_time"], unit="ms")
        numeric_cols = ["open", "high", "low", "close", "volume"]
        df_new[numeric_cols] = df_new[numeric_cols].apply(pd.to_numeric, errors="coerce")

        # t√≠nh c√°c c·ªôt c·∫ßn thi·∫øt
        df_new["delta_change"] = (df_new["close"] - df_new["open"]) / df_new["open"]

        # rename open_time ‚Üí timestamp tr∆∞·ªõc khi append
        df_new.rename(columns={"open_time": "timestamp"}, inplace=True)

        # append d·ªØ li·ªáu m·ªõi v√†o df_old
        if not df_old.empty:
            # tr√°nh duplicate n·∫øn
            if df_new["timestamp"].iloc[0] <= df_old["timestamp"].iloc[-1]:
                print(f"[{datetime.now()}] Candle already exists for {symbol}, skip")
                df = df_old.copy()
            else:
                df = pd.concat([df_old, df_new], ignore_index=True)
        else:
            df = df_new.copy()

        # t√≠nh l·∫°i average_volume_20 cho to√†n b·ªô b·∫£ng
        df["average_volume_20"] = df["volume"].rolling(20).mean().shift(1)

        # gi·ªØ c√°c c·ªôt c·∫ßn thi·∫øt
        cols_keep = ["timestamp", "open", "high", "low", "close", "volume", "delta_change", "average_volume_20"]
        df_out = df[cols_keep].copy()

        # l∆∞u Excel
        df_out.to_excel(excel_file, index=False)

    except Exception as e:
        print(f"[{datetime.now()}] ‚ö†Ô∏è Error fetching/appending candle for {symbol}: {e}")


def fetch_and_update_data(delay: float = 0.1):
    """
    Fetch 1 n·∫øn 15m m·ªõi nh·∫•t cho t·∫•t c·∫£ symbol v√† append v√†o Excel.
    Tr·∫£ v·ªÅ all_data dict {symbol: df} ƒë·ªÉ generate_report s·ª≠ d·ª•ng.
    - delay: ngh·ªâ gi·ªØa c√°c request ƒë·ªÉ tr√°nh b·ªã block
    """
    all_data = {}

    # üî• ch·ªâ g·ªçi 1 l·∫ßn
    server_ms = get_binance_server_time()
    time.sleep(2) 
    for symbol in SYMBOLS_LIST:
        try:
            print(f"[DEBUG] Fetching latest 1 candle for {symbol}...")

            excel_file = os.path.join(DATA_FOLDER, f"{symbol}_data.xlsx")
            fetch_append_latest_15m_candle(symbol, excel_file, server_ms=server_ms)

            # ƒë·ªçc l·∫°i to√†n b·ªô d·ªØ li·ªáu t·ª´ Excel ƒë·ªÉ d√πng cho report
            if os.path.exists(excel_file):
                df = pd.read_excel(excel_file)
                all_data[symbol] = df
                print(f"[DEBUG] {symbol}: {len(df)} rows loaded for report")
            else:
                print(f"[DEBUG] {symbol}: file not found after append")

        except Exception as e:
            print(f"[DEBUG] Error updating {symbol}: {e}")

        time.sleep(delay)  # ngh·ªâ gi·ªØa c√°c symbol

    print(f"[DEBUG] Fetched and updated data for {len(all_data)} symbols.")
    return all_data


def fetch_all_data(delay=0.2, retries=1):
    """
    L·∫•y d·ªØ li·ªáu cho t·∫•t c·∫£ c√°c ƒë·ªìng coin trong SYMBOLS_LIST.
    - delay: ngh·ªâ gi·ªØa c√°c l·∫ßn g·ªçi API (tr√°nh b·ªã ch·∫∑n).
    - retries: s·ªë l·∫ßn th·ª≠ l·∫°i n·∫øu l·ªói.
    """
    all_data = {}

    for symbol in SYMBOLS_LIST:   # ‚úÖ d√πng global SYMBOLS_LIST lu√¥n
        for attempt in range(retries):
            try:
                df = fetch_15m_closed_klines(symbol, limit=30)
                all_data[symbol] = df
                print(f"‚úÖ {symbol}: fetched {len(df)} rows")
                break
            except Exception as e:
                print(f"‚ö†Ô∏è Error fetching {symbol} (attempt {attempt+1}/{retries}): {e}")
                if attempt < retries - 1:
                    time.sleep(3)
                else:
                    print(f"‚ùå Skipping {symbol} sau {retries} l·∫ßn th·∫•t b·∫°i")

        time.sleep(delay)

    return all_data



def save_data_to_excel(all_data):
    # T·∫°o th∆∞ m·ª•c datafiles n·∫øu ch∆∞a c√≥
    if not os.path.exists('datafiles'):
        os.makedirs('datafiles')
    
    # L∆∞u d·ªØ li·ªáu v√†o t·ª´ng file Excel ri√™ng bi·ªát cho m·ªói ƒë·ªìng coin
    for symbol, data in all_data.items():
        # ƒê·∫∑t t√™n file theo t√™n ƒë·ªìng coin, v√≠ d·ª•: BTCUSDT.xlsx
        file_path = f'datafiles/{symbol}_data.xlsx'
        data.to_excel(file_path, index=False)

from datetime import datetime

def calculate_delta_change(open_price, close_price):
    """T√≠nh to√°n t·ª∑ l·ªá thay ƒë·ªïi gi√° t·ª´ m·ªü ƒë·∫øn ƒë√≥ng."""
    return round((close_price - open_price) / open_price, 4)  # L√†m tr√≤n ƒë·∫øn 4 ch·ªØ s·ªë sau d·∫•u ph·∫©y

def calculate_average_volume(df, window=20):
    """T√≠nh to√°n trung b√¨nh kh·ªëi l∆∞·ª£ng c·ªßa 20 n·∫øn g·∫ßn nh·∫•t."""
    return df['volume'].rolling(window=window).mean()

# debug function function
def generate_report(all_data):
    """T·∫°o b√°o c√°o v√† ghi v√†o file report.txt (c√≥ debug chi ti·∫øt)."""
    try:
        if not all_data:
            print("No data to generate report.")
            return
        
        with open("report.txt", "w") as file:
            for symbol, data in all_data.items():
                try:
                    last_row = data.iloc[-1]  # L·∫•y d√≤ng d·ªØ li·ªáu m·ªõi nh·∫•t
                    
                    last_delta_change = last_row.get('delta_change', None)
                    last_volume = last_row.get('volume', None)
                    avg_volume_20 = last_row.get('average_volume_20', None)
                    last_timestamp = last_row.get('timestamp', None)

                    # Check l·ªói NaN
                    if pd.isna(last_delta_change) or pd.isna(last_volume) or pd.isna(avg_volume_20):
                        continue
                    
                    # ƒê·ªãnh d·∫°ng timestamp
                    if isinstance(last_timestamp, pd.Timestamp):
                        formatted_timestamp = last_timestamp.strftime('%Y-%m-%d %H:%M:%S')
                    else:
                        formatted_timestamp = str(last_timestamp)  # fallback
                    
                    # ƒêi·ªÅu ki·ªán log
                    if last_delta_change > 0 and last_volume >= 4.3 * avg_volume_20:
                        line = f"{symbol} - Delta Change: {last_delta_change:.4f} at {formatted_timestamp}\n"
                        file.write(line)
                        print(f"[INFO] {symbol} th·ªèa ƒëi·ªÅu ki·ªán -> ghi v√†o report.")
                
                except Exception as e:
                    print(f"‚ùå Error processing {symbol}: {e}")
                
        print("‚úÖ Report generated and saved to report.txt.")
    except Exception as e:
        print(f"‚ùå Error generating report: {e}")

